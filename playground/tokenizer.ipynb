{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 124083, 6146, 3, 24474, 353, 49124, 6447, 32, 5, 55719, 59724, 15446, 93984]\n",
      "你好啊,这里是测试token embedding效果怎么样\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"BAAI/bge-m3\", cache_folder=\"../pretrained_models\")\n",
    "len(\n",
    "    model.encode(\n",
    "        \"你好啊，这里是测试token embedding效果怎么样\", output_value=\"token_embeddings\"\n",
    "    )\n",
    ")\n",
    "import sentencepiece as spm\n",
    "\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(\"./sentencepiece.bpe.model\")\n",
    "ids = sp.encode(\"你好啊，这里是测试token embedding效果怎么样\")\n",
    "print(ids)\n",
    "\n",
    "# 解码(将ID转换回文本)\n",
    "text = sp.decode(ids)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "821\n",
      "821\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"    output_states = self.auto_model(**trans_features, return_dict=False)\n",
    "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
    "    return self._call_impl(*args, **kwargs)\n",
    "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
    "    return forward_call(*args, **kwargs)\n",
    "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\", line 834, in forward\n",
    "    encoder_outputs = self.encoder(\n",
    "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
    "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
    "    return forward_call(*args, **kwargs)\n",
    "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\", line 411, in forward\n",
    "    self_attention_outputs = self.attention(\n",
    "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
    "    return self._call_impl(*args, **kwargs)\n",
    "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
    "    return forward_call(*args, **kwargs)\n",
    "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\", line 338, in forward\n",
    "    self_outputs = self.self(\n",
    "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
    "    return self._call_impl(*args, **kwargs)\n",
    "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
    "    return forward_call(*args, **kwargs)\n",
    "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\", line 211, in forward\n",
    "    value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
    "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\", line 175, in transpose_for_scores\n",
    "    x = x.view(new_x_shape)\n",
    "KeyboardInterrupt\"\"\"\n",
    "print(len(\n",
    "    model.encode(\n",
    "        text, output_value=\"token_embeddings\"\n",
    "    )\n",
    "))\n",
    "print(len(model.tokenize([text])['input_ids'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 140992, 454, 61340, 7, 2203, 15970, 5, 8913, 454, 51734, 132, 25442, 30145, 454, 88981, 30891, 4, 30646, 454, 61669, 1369, 17647, 11971, 16, 42724, 44, 64, 223, 42, 64, 98908, 64, 5612, 64, 6493, 50828, 363, 5, 963, 64, 46295, 9, 29102, 52467, 64, 1290, 206, 64, 10713, 64, 83279, 90, 64, 83279, 13, 5, 6493, 830, 13315, 423, 6460, 4, 23, 101, 5429, 11, 48398, 454, 85763, 454, 116120, 30646, 15970, 5, 454, 85763, 454, 116120, 88746, 61477, 7, 4, 16459, 10521, 10566, 7, 16, 42724, 44, 64, 223, 42, 64, 98908, 64, 5612, 64, 6493, 50828, 363, 5, 963, 64, 46295, 9, 29102, 52467, 64, 1290, 206, 64, 10713, 64, 83279, 90, 64, 83279, 13, 5, 6493, 830, 13315, 423, 8894, 4, 23, 101, 85763, 454, 116120, 30646, 40225, 454, 85763, 88746, 61477, 7, 4, 16459, 10521, 10566, 7, 16, 42724, 44, 64, 223, 42, 64, 98908, 64, 5612, 64, 6493, 50828, 363, 5, 963, 64, 46295, 9, 29102, 52467, 64, 215175, 1314, 64, 51734, 7, 64, 92595, 39, 454, 56942, 12014, 64, 51734, 214, 454, 92595, 39, 454, 56942, 12014, 5, 6493, 830, 13315, 6, 187716, 4, 23, 40225, 22, 587, 820, 454, 6056, 7077, 7, 2203, 15970, 5, 66332, 820, 132, 42724, 44, 64, 223, 42, 64, 98908, 64, 5612, 64, 6493, 50828, 363, 5, 963, 64, 46295, 9, 29102, 52467, 64, 1290, 206, 64, 10713, 64, 83279, 90, 64, 83279, 13, 5, 6493, 830, 13315, 423, 6460, 4, 23, 101, 5429, 11, 48398, 454, 85763, 454, 116120, 42724, 44, 64, 223, 42, 64, 98908, 64, 5612, 64, 6493, 50828, 363, 5, 963, 64, 46295, 9, 29102, 52467, 64, 1290, 206, 64, 10713, 64, 83279, 90, 64, 83279, 13, 5, 6493, 830, 13315, 423, 8894, 4, 23, 101, 85763, 454, 116120, 30646, 40225, 454, 85763, 88746, 61477, 7, 4, 16459, 10521, 10566, 7, 16, 42724, 44, 64, 223, 42, 64, 98908, 64, 5612, 64, 6493, 50828, 363, 5, 963, 64, 46295, 9, 29102, 52467, 64, 215175, 1314, 64, 51734, 7, 64, 92595, 39, 454, 56942, 12014, 64, 51734, 214, 454, 92595, 39, 454, 56942, 12014, 5, 6493, 830, 13315, 201, 1662, 4, 23, 40225, 15970, 454, 257, 62500, 454, 6056, 7077, 7, 2203, 15970, 5, 257, 62500, 132, 42724, 44, 64, 223, 42, 64, 98908, 64, 5612, 64, 6493, 50828, 363, 5, 963, 64, 46295, 9, 29102, 52467, 64, 1290, 206, 64, 10713, 64, 83279, 90, 64, 83279, 13, 5, 6493, 830, 13315, 423, 6460, 4, 23, 101, 5429, 11, 48398, 454, 85763, 454, 116120, 30646, 15970, 5, 454, 85763, 454, 116120, 88746, 61477, 7, 4, 16459, 10521, 10566, 7, 16, 42724, 44, 64, 223, 42, 64, 98908, 64, 5612, 64, 6493, 50828, 363, 5, 963, 64, 46295, 9, 29102, 52467, 64, 1290, 206, 64, 10713, 64, 83279, 90, 64, 83279, 13, 5, 6493, 830, 13315, 423, 8894, 4, 23, 101, 85763, 454, 116120, 30646, 40225, 454, 85763, 88746, 61477, 7, 4, 16459, 10521, 10566, 7, 16, 42724, 44, 64, 223, 42, 64, 98908, 64, 5612, 64, 6493, 50828, 363, 5, 963, 64, 46295, 9, 29102, 52467, 64, 215175, 1314, 64, 51734, 7, 64, 92595, 39, 454, 56942, 12014, 64, 51734, 214, 454, 92595, 39, 454, 56942, 12014, 5, 6493, 830, 13315, 6, 128222, 4, 23, 40225, 15970, 454, 6056, 7077, 7, 2203, 15970, 5, 39379, 132, 42724, 44, 64, 223, 42, 64, 98908, 64, 5612, 64, 6493, 50828, 363, 5, 963, 64, 46295, 9, 29102, 52467, 64, 1290, 206, 64, 10713, 64, 83279, 90, 64, 83279, 13, 5, 6493, 830, 13315, 423, 6460, 4, 23, 101, 5429, 11, 48398, 454, 85763, 454, 116120, 30646, 15970, 5, 454, 85763, 454, 116120, 88746, 61477, 7, 4, 16459, 10521, 10566, 7, 16, 42724, 44, 64, 223, 42, 64, 98908, 64, 5612, 64, 6493, 50828, 363, 5, 963, 64, 46295, 9, 29102, 52467, 64, 1290, 206, 64, 10713, 64, 83279, 90, 64, 83279, 13, 5, 6493, 830, 13315, 423, 8894, 4, 23, 101, 85763, 454, 116120, 30646, 40225, 454, 85763, 88746, 61477, 7, 4, 16459, 10521, 10566, 7, 16, 42724, 44, 64, 223, 42, 64, 98908, 64, 5612, 64, 6493, 50828, 363, 5, 963, 64, 46295, 9, 29102, 52467, 64, 215175, 1314, 64, 51734, 7, 64, 92595, 39, 454, 56942, 12014, 64, 51734, 214, 454, 92595, 39, 454, 56942, 12014, 5, 6493, 830, 13315, 112713, 4, 23, 40225, 34292, 454, 5259, 56, 2203, 15970, 5, 30145, 78381, 454, 2472, 454, 12064, 2109, 132, 39379, 5, 27494, 13, 132, 15080, 555, 454, 61340, 7, 16, 16, 42724, 44, 64, 223, 42, 64, 98908, 64, 5612, 64, 6493, 50828, 363, 5, 963, 64, 46295, 9, 29102, 52467, 64, 215175, 1314, 64, 51734, 7, 64, 92595, 39, 454, 56942, 12014, 64, 51734, 214, 454, 92595, 39, 454, 56942, 12014, 5, 6493, 830, 13315, 36213, 4, 23, 3900, 78381, 454, 2472, 454, 12064, 2109, 1022, 2203, 1022, 5, 22751, 132, 54936, 454, 425, 454, 2420, 1081, 16, 227247, 44851, 9167, 18, 2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "ids = model.tokenize([text])['input_ids'][0].cpu().numpy()\n",
    "vertical_array = list(np.array(ids))  # 直接使用一维数组，不需要reshape\n",
    "print(vertical_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2389, -0.7111, -0.5542,  ..., -0.2605, -0.7423,  0.0350],\n",
       "        [-0.1289,  0.0333, -0.1997,  ..., -0.1655, -0.5441,  0.0043],\n",
       "        [-0.4825, -0.2598, -0.8775,  ...,  0.2721, -0.4147,  0.3074],\n",
       "        ...,\n",
       "        [ 0.2017, -0.2470, -0.0944,  ...,  0.0136, -1.4031,  0.5232],\n",
       "        [ 0.2348, -0.1821, -0.6745,  ..., -0.0888, -1.1853, -0.1986],\n",
       "        [-0.5145,  0.7450,  0.8630,  ..., -0.2473, -1.6941,  0.1772]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encode(text, output_value=\"token_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = [0] + [x + 1 for x in sp.encode(text)] + [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token == vertical_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[-1.1362, -0.5443, -0.7022,  ..., -0.1484, -0.7644,  0.1470],\n",
      "        [-0.1448,  0.1383, -0.2100,  ..., -0.0300, -0.5197,  0.1691],\n",
      "        [-0.5280, -0.1944, -0.9211,  ...,  0.3161, -0.4270,  0.3508],\n",
      "        ...,\n",
      "        [ 0.0947, -0.2599, -0.0911,  ...,  0.1008, -1.5049,  0.5348],\n",
      "        [ 0.4396, -0.0976, -0.8032,  ...,  0.1474, -1.0879, -0.2006],\n",
      "        [-0.4703,  0.8040,  0.8686,  ..., -0.2453, -1.5886,  0.3813]],\n",
      "       device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"    output_states = self.auto_model(**trans_features, return_dict=False)\n",
    "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
    "    return self._call_impl(*args, **kwargs)\n",
    "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
    "    return forward_call(*args, **kwargs)\n",
    "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\", line 834, in forward\n",
    "    encoder_outputs = self.encoder(\n",
    "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
    "    return self._call_impl(*args, **kwargs)\n",
    "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
    "    return forward_call(*args, **kwargs)\n",
    "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\", line 522, in forward\n",
    "    layer_outputs = layer_module(\n",
    "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
    "    return self._call_impl(*args, **kwargs)\n",
    "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
    "    return forward_call(*args, **kwargs)\n",
    "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\", line 411, in forward\n",
    "    self_attention_outputs = self.attention(\n",
    "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
    "    return self._call_impl(*args, **kwargs)\n",
    "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
    "    return forward_call(*args, **kwargs)\n",
    "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\", line 338, in forward\n",
    "    self_outputs = self.self(\n",
    "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n",
    "    return self._call_impl(*args, **kwargs)\n",
    "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n",
    "    return forward_call(*args, **kwargs)\n",
    "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\", line 211, in forward\n",
    "    value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
    "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\", line 175, in transpose_for_scores\n",
    "    x = x.view(new_x_shape)\n",
    "KeyboardInterrupt\"\"\"\n",
    "print(\n",
    "    model.encode(\n",
    "        [text], output_value=\"token_embeddings\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "import torch\n",
    "with torch.no_grad():\n",
    "    data = model.encode(\n",
    "        [text,'你好'], output_value=\"token_embeddings\"\n",
    ")\n",
    "torch.save(data[0].cpu(), \"token_embeddings0.pt\")\n",
    "torch.save(data[1].cpu(), \"token_embeddings1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 0 shape: torch.Size([1017, 1024])\n",
      "Embedding 1 shape: torch.Size([4, 1024])\n",
      "Embedding 0 dtype: torch.float32\n",
      "Embedding 1 dtype: torch.float32\n",
      "Actual data size of embedding 0: 4165632 bytes\n",
      "Actual data size of embedding 1: 16384 bytes\n",
      "File size of token_embeddings0.pt: 8332494 bytes\n",
      "File size of token_embeddings1.pt: 8332494 bytes\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "# 加载保存的embeddings\n",
    "embed0 = torch.load(\"token_embeddings0.pt\")\n",
    "embed1 = torch.load(\"token_embeddings1.pt\")\n",
    "\n",
    "# 打印形状和数据类型\n",
    "print(\"Embedding 0 shape:\", embed0.shape)\n",
    "print(\"Embedding 1 shape:\", embed1.shape)\n",
    "print(\"Embedding 0 dtype:\", embed0.dtype)\n",
    "print(\"Embedding 1 dtype:\", embed1.dtype)\n",
    "\n",
    "# 计算实际数据大小\n",
    "size0 = embed0.nelement() * embed0.element_size()\n",
    "size1 = embed1.nelement() * embed1.element_size()\n",
    "\n",
    "print(f\"Actual data size of embedding 0: {size0} bytes\")\n",
    "print(f\"Actual data size of embedding 1: {size1} bytes\")\n",
    "\n",
    "# 获取文件大小\n",
    "file_size0 = os.path.getsize(\"token_embeddings0.pt\")\n",
    "file_size1 = os.path.getsize(\"token_embeddings1.pt\")\n",
    "\n",
    "print(f\"File size of token_embeddings0.pt: {file_size0} bytes\")\n",
    "print(f\"File size of token_embeddings1.pt: {file_size1} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# 假设 embed0 和 embed1 是您的PyTorch张量\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 转换为numpy数组并保存\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding0.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43membed0\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      7\u001b[0m np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding1.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m, embed1\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# 检查文件大小\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 假设 embed0 和 embed1 是您的PyTorch张量\n",
    "\n",
    "# 转换为numpy数组并保存\n",
    "np.save(\"embedding0.npy\", embed0.numpy())\n",
    "np.save(\"embedding1.npy\", embed1.numpy())\n",
    "\n",
    "# 检查文件大小\n",
    "import os\n",
    "print(f\"NPY file size for embedding 0: {os.path.getsize('embedding0.npy')} bytes\")\n",
    "print(f\"NPY file size for embedding 1: {os.path.getsize('embedding1.npy')} bytes\")\n",
    "\n",
    "# 读取测试\n",
    "loaded_embed0 = np.load(\"embedding0.npy\")\n",
    "loaded_embed1 = np.load(\"embedding1.npy\")\n",
    "\n",
    "print(f\"Loaded embedding 0 shape: {loaded_embed0.shape}\")\n",
    "print(f\"Loaded embedding 1 shape: {loaded_embed1.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor1 = torch.load(\"token_embeddings0.pt\")\n",
    "tensor2 = torch.load(\"token_embeddings1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1024])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5,\n",
       " 124083,\n",
       " 6146,\n",
       " 3,\n",
       " 24474,\n",
       " 353,\n",
       " 49124,\n",
       " 6447,\n",
       " 32,\n",
       " 5,\n",
       " 55719,\n",
       " 59724,\n",
       " 15446,\n",
       " 93984]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sp.encode(\"你好啊，这里是测试token embedding效果怎么样\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' ⁇ '"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.decode([0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5,\n",
       " 124083,\n",
       " 6146,\n",
       " 3,\n",
       " 24474,\n",
       " 353,\n",
       " 49124,\n",
       " 6447,\n",
       " 32,\n",
       " 5,\n",
       " 55719,\n",
       " 59724,\n",
       " 15446,\n",
       " 93984]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.encode(\"你好啊，这里是测试token embedding效果怎么样\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[     0,      6, 124084,   6147,      4,  24475,    354,  49125,   6448,\n",
       "             33,      6,  55720,  59725,  15447,  93985,      2]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tokenize([\"你好啊，这里是测试token embedding效果怎么样\"])['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
