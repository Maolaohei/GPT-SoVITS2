{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(\"./sentencepiece.bpe.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35377, 6660]\n",
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "ids = sp.encode(\"Hello World\")\n",
    "print(ids)\n",
    "\n",
    "# 解码(将ID转换回文本)\n",
    "text = sp.decode(ids)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = torch.nn.Embedding(250000, 256)\n",
    "emb.weight.data.uniform_(-0.1, 0.1)\n",
    "emb.weight.data.shape\n",
    "embedding = emb(torch.tensor(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 256])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 原来的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前目录: /workspaces/GPT-SoVITS2/playground\n",
      "/workspaces/GPT-SoVITS2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "print(\"当前目录:\", current_dir)\n",
    "# 获取当前文件的父目录\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "sys.path.append(parent_dir)\n",
    "print(parent_dir)\n",
    "from GPT_SoVITS.AR.models.t2s_model import Text2SemanticDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Text2SemanticDecoder({\n",
    "    \"model\": {\n",
    "        \"n_layer\": 24,\n",
    "        \"hidden_dim\": 768,\n",
    "        \"head\": 16,\n",
    "        \"num_codebook\": 8,\n",
    "        \"p_dropout\": 0.0,\n",
    "        \"vocab_size\": 4097,\n",
    "        \"pad_val\": 4096,\n",
    "        \"embedding_dim\": 768,\n",
    "        \"dropout\": 0.0,\n",
    "        \"EOS\": 4096,\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xy_embedded shape: torch.Size([2, 19, 768])\n",
      "x_mask shape: torch.Size([2, 10])\n",
      "y_mask shape: torch.Size([2, 9])\n",
      "xy_mask shape: torch.Size([2, 19])\n",
      "xy_len: tensor([19, 18])\n",
      "\n",
      "xy_mask for batch idx 1:\n",
      "tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True, False])\n",
      "\n",
      "x_mask:\n",
      "tensor([[True, True, True, True, True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True]])\n",
      "\n",
      "y_mask:\n",
      "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True,  True,  True,  True, False]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 假设的输入数据\n",
    "x = torch.tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 3, 3, 5, 5, 3, 4, 1, 67, 2]])\n",
    "y = torch.tensor(\n",
    "    [[11, 12, 13, 14, 15, 16, 17, 18, 19], [11, 12, 13, 14, 15, 3, 61, 3, 325]]\n",
    ")\n",
    "x_len = torch.tensor([10, 10])\n",
    "y_len = torch.tensor([9, 8])\n",
    "\n",
    "# 创建text和speech的Embedding层\n",
    "text_vocab_size = 250000  # 假设的文本词汇表大小\n",
    "speech_vocab_size = 250000  # 假设的语音词汇表大小\n",
    "embedding_dim = 768  # 假设的嵌入维度\n",
    "\n",
    "text_embedding = nn.Embedding(text_vocab_size, embedding_dim)\n",
    "speech_embedding = nn.Embedding(speech_vocab_size, embedding_dim)\n",
    "\n",
    "\n",
    "# 计算embedding的函数\n",
    "def compute_embedding(tokens, lengths, embedding_layer):\n",
    "    batch_size, max_len = tokens.shape\n",
    "    mask = torch.arange(max_len).expand(batch_size, max_len) < lengths.unsqueeze(1)\n",
    "    embedded = embedding_layer(tokens) * mask.unsqueeze(-1).float()\n",
    "    return embedded\n",
    "\n",
    "\n",
    "# 计算x和y的embedding\n",
    "x_embedded = compute_embedding(x, x_len, text_embedding)\n",
    "y_embedded = compute_embedding(y, y_len, speech_embedding)\n",
    "\n",
    "# 正确拼接embedding\n",
    "batch_size = x.shape[0]\n",
    "max_len = x_len.max() + y_len.max()\n",
    "xy_embedded = torch.zeros(\n",
    "    (batch_size, max_len, embedding_dim), device=x_embedded.device\n",
    ")\n",
    "\n",
    "for i in range(batch_size):\n",
    "    xy_embedded[i, : x_len[i]] = x_embedded[i, : x_len[i]]\n",
    "    xy_embedded[i, x_len[i] : x_len[i] + y_len[i]] = y_embedded[i, : y_len[i]]\n",
    "\n",
    "# 计算x_mask\n",
    "x_mask = torch.arange(x.shape[1]).expand(batch_size, -1) < x_len.unsqueeze(1)\n",
    "y_mask = torch.arange(y.shape[1]).expand(batch_size, -1) < y_len.unsqueeze(1)\n",
    "# 计算正确的xy_mask\n",
    "xy_mask = torch.zeros((batch_size, max_len), dtype=torch.bool)\n",
    "for i in range(batch_size):\n",
    "    xy_mask[i, : x_len[i] + y_len[i]] = True\n",
    "\n",
    "# 计算xy_len\n",
    "xy_len = x_len + y_len\n",
    "\n",
    "print(\"xy_embedded shape:\", xy_embedded.shape)\n",
    "print(\"x_mask shape:\", x_mask.shape)\n",
    "print(\"y_mask shape:\", y_mask.shape)\n",
    "print(\"xy_mask shape:\", xy_mask.shape)\n",
    "print(\"xy_len:\", xy_len)\n",
    "\n",
    "# 打印第二个样本（batch idx = 1）的mask\n",
    "print(\"\\nxy_mask for batch idx 1:\")\n",
    "print(xy_mask[1])\n",
    "\n",
    "# 打印x_mask\n",
    "print(\"\\nx_mask:\")\n",
    "print(x_mask)\n",
    "print(\"\\ny_mask:\")\n",
    "print(y_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
       "        [ 1,  3,  3,  5,  5,  3,  4,  1, 67,  2]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models import qwen2\n",
    "from transformers import AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "    \"Qwen/Qwen2-0.5B\",\n",
    ")\n",
    "config.hidden_size = 768\n",
    "config.num_hidden_layers = 16\n",
    "config.max_window_layers = 16\n",
    "config.num_attention_heads = 12\n",
    "model = qwen2.Qwen2Model(config=config).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = model(inputs_embeds=xy_embedded.to(\"cuda\"), attention_mask=xy_mask.to(\"cuda\"))\n",
    "res2 = model(inputs_embeds=xy_embedded.to(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True,  ...,  True,  True,  True],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False]], device='cuda:0')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1.last_hidden_state[0] == res2.last_hidden_state[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]])\n",
    "y_mask_int = torch.tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]])\n",
    "y = y.type(torch.int64) * (1 - y_mask_int)\n",
    "targets = torch.nn.functional.pad(y, (0, 1), value=0) + 4096 * torch.nn.functional.pad(\n",
    "            y_mask_int, (0, 1), value=1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, targets = targets[:, :-1], targets[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   1,    2,    3,    4,    5,    6,    7,    8,    9,   10],\n",
       "        [   1,    2,    3,    4,    5,    6,    7,    8,    9, 4096]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]])\n",
    "y_mask = torch.tensor([[True, True, True, True, True, True, True, True, True, True], [True, True, True, True, True, True, True, True, True, False]])\n",
    "EOS = 4096\n",
    "# mask为False的地方变成EOS\n",
    "y = torch.where(y_mask, y, EOS)\n",
    "# 给y后面添加EOS\n",
    "targets = torch.nn.functional.pad(y, (0, 1), value=EOS)\n",
    "y, targets = targets[:, :-1], targets[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   1,    2,    3,    4,    5,    6,    7,    8,    9,   10],\n",
       "        [   1,    2,    3,    4,    5,    6,    7,    8,    9, 4096]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   2,    3,    4,    5,    6,    7,    8,    9,   10, 4096],\n",
       "        [   2,    3,    4,    5,    6,    7,    8,    9, 4096, 4096]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "qwen_config = AutoConfig.from_pretrained(\n",
    "    \"Qwen/Qwen2-72b\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "IGNORE_ID = -1\n",
    "text_token_len = torch.tensor([10, 10])\n",
    "speech_token_len = torch.tensor([9, 5])\n",
    "speech_token = torch.tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9], [1, 2, 3, 4, 5, 6, 7, 8, 9]])\n",
    "lm_target = [torch.tensor([IGNORE_ID] * (2 + text_token_len[i]) + speech_token[i, :speech_token_len[i]].tolist() + [4096]) for i in range(text_token_len.size(0))]\n",
    "lm_target = pad_sequence(lm_target, batch_first=True, padding_value=IGNORE_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
       "            1,    2,    3,    4,    5,    6,    7,    8,    9, 4096],\n",
       "        [  -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
       "            1,    2,    3,    4,    5, 4096,   -1,   -1,   -1,   -1]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_target"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
