{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import traceback\n",
    "import numpy as np\n",
    "import torch\n",
    "import sentencepiece as spm\n",
    "import librosa\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "sys.path.append(parent_dir)\n",
    "from GPT_SoVITS.module.mel_processing import spectrogram_torch\n",
    "\n",
    "from tools.my_utils import load_audio\n",
    "\n",
    "class TextAudioSpeakerLoader(torch.utils.data.Dataset):\n",
    "    def tokenize_text(self, text):\n",
    "        token = [0] + [x + 1 for x in self.sp.encode(text)] + [2]\n",
    "        return token\n",
    "\n",
    "    def __init__(self, hparams, val=False):\n",
    "        self.sp = spm.SentencePieceProcessor()\n",
    "        self.sp.load(\"../pretrained_models/sentencepiece.bpe.model\")\n",
    "        exp_dir = hparams.exp_dir\n",
    "        todo = []\n",
    "        self.audiopaths_text = []\n",
    "        self.lengths = []\n",
    "        for root, dirs, files in os.walk(exp_dir):\n",
    "            for file in files:\n",
    "                if file.endswith(\".txt\"):\n",
    "                    index_folder = os.path.relpath(root, exp_dir)\n",
    "                    file_path = os.path.join(root, file)\n",
    "\n",
    "                    # 尝试不同的编码\n",
    "                    encodings = [\"utf-8\", \"gbk\", \"gb2312\", \"utf-16\"]\n",
    "                    for encoding in encodings:\n",
    "                        try:\n",
    "                            with open(file_path, \"r\", encoding=encoding) as f:\n",
    "                                lines = f.readlines()\n",
    "                            break  # 如果成功读取，跳出循环\n",
    "                        except UnicodeDecodeError:\n",
    "                            continue  # 如果解码失败，尝试下一个编码\n",
    "                    else:\n",
    "                        print(f\"无法解码文件 {file_path}，跳过此文件\")\n",
    "                        continue  # 如果所有编码都失败，跳过此文件\n",
    "\n",
    "                    for line in lines:\n",
    "                        try:\n",
    "                            spk_name, wav_name, text = line.split(\"|\")\n",
    "                            todo.append([spk_name, wav_name, text, index_folder])\n",
    "                        except Exception:\n",
    "                            print(line)\n",
    "        for data in todo:\n",
    "            _, wav_name, text, index_folder = data\n",
    "            audio_path = os.path.join(exp_dir, index_folder, wav_name)\n",
    "            speech_token_path = audio_path + \".npy\"\n",
    "            bert_path = audio_path + \".pt\"\n",
    "            wav_path = audio_path + \".wav\"\n",
    "            if (\n",
    "                os.path.exists(speech_token_path)\n",
    "                and os.path.exists(bert_path)\n",
    "                and os.path.exists(wav_path)\n",
    "            ):\n",
    "                try:\n",
    "                    duration = librosa.get_duration(filename=wav_path)  # noqa: F821\n",
    "                    self.lengths.append(math.ceil(duration * 50))\n",
    "                except Exception as e:\n",
    "                    print(f\"无法处理文件 {wav_path}：{str(e)}\")\n",
    "                    continue\n",
    "                self.audiopaths_text.append([audio_path, text])\n",
    "\n",
    "        self.max_wav_value = hparams.max_wav_value\n",
    "        self.sampling_rate = hparams.sampling_rate\n",
    "        self.filter_length = hparams.filter_length\n",
    "        self.hop_length = hparams.hop_length\n",
    "        self.win_length = hparams.win_length\n",
    "        self.sampling_rate = hparams.sampling_rate\n",
    "        self.val = val\n",
    "\n",
    "        \"\"\"\n",
    "        @misc{picard2023torchmanualseed3407needinfluencerandom,\n",
    "        title={Torch.manual_seed(3407) is all you need: On the influence of random seeds in deep learning architectures for computer vision}, \n",
    "        author={David Picard},\n",
    "        year={2023},\n",
    "        eprint={2109.08203},\n",
    "        archivePrefix={arXiv},\n",
    "        primaryClass={cs.CV},\n",
    "        url={https://arxiv.org/abs/2109.08203}, \n",
    "        }\n",
    "        \"\"\"\n",
    "        random.seed(3407)  # 3407 is all you need\n",
    "\n",
    "        random.shuffle(self.audiopaths_text)\n",
    "        print(\"wav_data_len:\", len(self.audiopaths_text))\n",
    "\n",
    "    def get_audio_text_speaker_pair(self, audiopath_text):\n",
    "        audiopath, text = audiopath_text\n",
    "        text_token = self.tokenize_text(text)\n",
    "        try:\n",
    "            spec, wav = self.get_audio(audiopath + \".wav\")\n",
    "            speech_token = np.load(audiopath + \".npy\")\n",
    "            speech_token = torch.from_numpy(speech_token)\n",
    "            min_length = min(speech_token.shape[-1], spec.shape[-1])\n",
    "            speech_token = speech_token[..., :min_length]\n",
    "            spec = spec[..., :min_length]\n",
    "        except Exception:\n",
    "            traceback.print_exc()\n",
    "            spec = torch.zeros(1025, 100)\n",
    "            wav = torch.zeros(1, 100 * self.hop_length)\n",
    "            speech_token = torch.zeros(1, 100)\n",
    "            text_token = text_token[-1:]\n",
    "            print(\"load error!!!!!!\", audiopath)\n",
    "        return (speech_token, spec, wav, text_token)\n",
    "\n",
    "    def get_audio(self, filename):\n",
    "        audio_array = load_audio(filename, self.sampling_rate)\n",
    "        audio = torch.FloatTensor(audio_array)\n",
    "        audio = audio.unsqueeze(0)\n",
    "        spec = spectrogram_torch(\n",
    "            audio,\n",
    "            self.filter_length,\n",
    "            self.sampling_rate,\n",
    "            self.hop_length,\n",
    "            self.win_length,\n",
    "            center=False,\n",
    "        )\n",
    "        spec = torch.squeeze(spec, 0)\n",
    "        return spec, audio\n",
    "\n",
    "    def get_sid(self, sid):\n",
    "        sid = torch.LongTensor([int(sid)])\n",
    "        return sid\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # with torch.no_grad():\n",
    "        return self.get_audio_text_speaker_pair(self.audiopaths_text[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audiopaths_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wav_data_len: 16006\n",
      "数据集大小: 16006\n",
      "语音标记形状: torch.Size([324])\n",
      "频谱图形状: torch.Size([1025, 324])\n",
      "波形形状: torch.Size([1, 207920])\n",
      "文本标记: [0, 6, 10330, 216765, 886, 130668, 4, 35922, 274, 8856, 887, 7402, 83855, 4011, 25840, 4, 63211, 184120, 274, 2058, 4011, 2391, 4695, 6042, 4, 1036, 4502, 32, 2]\n",
      "音频已导出为 output_audio.wav\n"
     ]
    }
   ],
   "source": [
    "class SimpleHparams:\n",
    "    def __init__(self):\n",
    "        self.exp_dir = \"../dataset\"\n",
    "        self.max_wav_value = 32768.0\n",
    "        self.sampling_rate = 32000\n",
    "        self.filter_length = 2048\n",
    "        self.hop_length = 640\n",
    "        self.win_length = 2048\n",
    "\n",
    "# 创建 hparams 实例\n",
    "hparams = SimpleHparams()\n",
    "\n",
    "# 创建 TextAudioSpeakerLoader 实例\n",
    "dataset = TextAudioSpeakerLoader(hparams)\n",
    "\n",
    "# 打印数据集的大小\n",
    "print(f\"数据集大小: {len(dataset)}\")\n",
    "\n",
    "# 获取第一个样本\n",
    "if len(dataset) > 0:\n",
    "    sample = dataset[1]\n",
    "    speech_token, spec, wav, text_token = sample\n",
    "    \n",
    "    print(f\"语音标记形状: {speech_token.shape}\")\n",
    "    print(f\"频谱图形状: {spec.shape}\")\n",
    "    print(f\"波形形状: {wav.shape}\")\n",
    "    print(f\"文本标记: {text_token}\")\n",
    "    \n",
    "    # 保存wav到文件\n",
    "    import soundfile as sf\n",
    "    import numpy as np\n",
    "    \n",
    "    # 确保wav是一个numpy数组，并且是float32类型\n",
    "    if isinstance(wav, torch.Tensor):\n",
    "        wav = wav.numpy()\n",
    "    wav = wav.astype(np.float32)\n",
    "    \n",
    "    # 确保音频数据在-1到1之间\n",
    "    wav = np.clip(wav, -1, 1)\n",
    "    \n",
    "    # 导出为WAV文件\n",
    "    try:\n",
    "        sf.write('output_audio.wav', wav.squeeze(), hparams.sampling_rate, subtype='FLOAT')\n",
    "        print(\"音频已导出为 output_audio.wav\")\n",
    "    except Exception as e:\n",
    "        print(f\"导出音频时出错: {str(e)}\")\n",
    "else:\n",
    "    print(\"数据集为空\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextAudioCollate:\n",
    "    def __init__(self, return_ids=False):\n",
    "        self.return_ids = return_ids\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        # 按照频谱图长度排序\n",
    "        _, ids_sorted_decreasing = torch.sort(\n",
    "            torch.LongTensor([x[1].size(1) for x in batch]),\n",
    "            dim=0, descending=True\n",
    "        )\n",
    "\n",
    "        max_speech_len = max([x[0].size(0) for x in batch])\n",
    "        max_spec_len = max([x[1].size(1) for x in batch])\n",
    "        max_wav_len = max([x[2].size(1) for x in batch])\n",
    "        max_text_len = max([len(x[3]) for x in batch])\n",
    "\n",
    "        speech_lengths = torch.LongTensor(len(batch))\n",
    "        spec_lengths = torch.LongTensor(len(batch))\n",
    "        wav_lengths = torch.LongTensor(len(batch))\n",
    "        text_lengths = torch.LongTensor(len(batch))\n",
    "\n",
    "        speech_padded = torch.LongTensor(len(batch), max_speech_len)\n",
    "        spec_padded = torch.FloatTensor(len(batch), 1025, max_spec_len)\n",
    "        wav_padded = torch.FloatTensor(len(batch), 1, max_wav_len)\n",
    "        text_padded = torch.LongTensor(len(batch), max_text_len)\n",
    "\n",
    "        speech_padded.zero_()\n",
    "        spec_padded.zero_()\n",
    "        wav_padded.zero_()\n",
    "        text_padded.zero_()\n",
    "\n",
    "        for i in range(len(ids_sorted_decreasing)):\n",
    "            row = batch[ids_sorted_decreasing[i]]\n",
    "\n",
    "            speech = row[0]\n",
    "            speech_padded[i, :speech.size(0)] = speech\n",
    "            speech_lengths[i] = speech.size(0)\n",
    "\n",
    "            spec = row[1]\n",
    "            spec_padded[i, :, :spec.size(1)] = spec\n",
    "            spec_lengths[i] = spec.size(1)\n",
    "\n",
    "            wav = row[2]\n",
    "            wav_padded[i, :, :wav.size(1)] = wav\n",
    "            wav_lengths[i] = wav.size(1)\n",
    "\n",
    "            text = torch.LongTensor(row[3])\n",
    "            text_padded[i, :text.size(0)] = text\n",
    "            text_lengths[i] = text.size(0)\n",
    "\n",
    "        if self.return_ids:\n",
    "            return (\n",
    "                speech_padded, speech_lengths, spec_padded, spec_lengths,\n",
    "                wav_padded, wav_lengths, text_padded, text_lengths, ids_sorted_decreasing\n",
    "            )\n",
    "        return (\n",
    "            speech_padded, speech_lengths, spec_padded, spec_lengths,\n",
    "            wav_padded, wav_lengths, text_padded, text_lengths\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speech_padded shape: torch.Size([4, 237]), type: torch.int64\n",
      "speech_lengths shape: torch.Size([4]), type: torch.int64\n",
      "spec_padded shape: torch.Size([4, 1025, 237]), type: torch.float32\n",
      "spec_lengths shape: torch.Size([4]), type: torch.int64\n",
      "wav_padded shape: torch.Size([4, 1, 151820]), type: torch.float32\n",
      "wav_lengths shape: torch.Size([4]), type: torch.int64\n",
      "text_padded shape: torch.Size([4, 21]), type: torch.int64\n",
      "text_lengths shape: torch.Size([4]), type: torch.int64\n",
      "\n",
      "Sample 0:\n",
      "  Speech length: 237, Padded speech shape: torch.Size([237])\n",
      "  Spec length: 237, Padded spec shape: torch.Size([1025, 237])\n",
      "  Wav length: 151820, Padded wav shape: torch.Size([1, 151820])\n",
      "  Text length: 20, Padded text shape: torch.Size([21])\n",
      "\n",
      "Sample 1:\n",
      "  Speech length: 226, Padded speech shape: torch.Size([237])\n",
      "  Spec length: 226, Padded spec shape: torch.Size([1025, 237])\n",
      "  Wav length: 144780, Padded wav shape: torch.Size([1, 151820])\n",
      "  Text length: 21, Padded text shape: torch.Size([21])\n",
      "\n",
      "Sample 2:\n",
      "  Speech length: 108, Padded speech shape: torch.Size([237])\n",
      "  Spec length: 108, Padded spec shape: torch.Size([1025, 237])\n",
      "  Wav length: 69540, Padded wav shape: torch.Size([1, 151820])\n",
      "  Text length: 6, Padded text shape: torch.Size([21])\n",
      "\n",
      "Sample 3:\n",
      "  Speech length: 71, Padded speech shape: torch.Size([237])\n",
      "  Spec length: 71, Padded spec shape: torch.Size([1025, 237])\n",
      "  Wav length: 46000, Padded wav shape: torch.Size([1, 151820])\n",
      "  Text length: 5, Padded text shape: torch.Size([21])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "# 创建 collate 函数实例\n",
    "collate_fn = TextAudioCollate()\n",
    "\n",
    "# 创建 DataLoader\n",
    "batch_size = 4  # 使用小批量以便于观察\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# 获取一个批次的数据\n",
    "batch = next(iter(dataloader))\n",
    "\n",
    "# 解包批次数据\n",
    "speech_padded, speech_lengths, spec_padded, spec_lengths, wav_padded, wav_lengths, text_padded, text_lengths = batch\n",
    "\n",
    "# 打印每个张量的形状和类型\n",
    "print(f\"speech_padded shape: {speech_padded.shape}, type: {speech_padded.dtype}\")\n",
    "print(f\"speech_lengths shape: {speech_lengths.shape}, type: {speech_lengths.dtype}\")\n",
    "print(f\"spec_padded shape: {spec_padded.shape}, type: {spec_padded.dtype}\")\n",
    "print(f\"spec_lengths shape: {spec_lengths.shape}, type: {spec_lengths.dtype}\")\n",
    "print(f\"wav_padded shape: {wav_padded.shape}, type: {wav_padded.dtype}\")\n",
    "print(f\"wav_lengths shape: {wav_lengths.shape}, type: {wav_lengths.dtype}\")\n",
    "print(f\"text_padded shape: {text_padded.shape}, type: {text_padded.dtype}\")\n",
    "print(f\"text_lengths shape: {text_lengths.shape}, type: {text_lengths.dtype}\")\n",
    "\n",
    "# 验证填充是否正确\n",
    "for i in range(batch_size):\n",
    "    print(f\"\\nSample {i}:\")\n",
    "    print(f\"  Speech length: {speech_lengths[i]}, Padded speech shape: {speech_padded[i].shape}\")\n",
    "    print(f\"  Spec length: {spec_lengths[i]}, Padded spec shape: {spec_padded[i].shape}\")\n",
    "    print(f\"  Wav length: {wav_lengths[i]}, Padded wav shape: {wav_padded[i].shape}\")\n",
    "    print(f\"  Text length: {text_lengths[i]}, Padded text shape: {text_padded[i].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已保存音频文件：output_wavs/sample_0.wav\n",
      "已保存音频文件：output_wavs/sample_1.wav\n",
      "已保存音频文件：output_wavs/sample_2.wav\n",
      "已保存音频文件：output_wavs/sample_3.wav\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import os\n",
    "\n",
    "# 创建一个保存音频文件的目录\n",
    "output_dir = \"output_wavs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for i in range(batch_size):\n",
    "    # 获取当前样本的音频数据和长度\n",
    "    wav = wav_padded[i, :, :]  # 只取有效长度的部分\n",
    "    \n",
    "    # 将张量转换为CPU上的float32类型\n",
    "    wav = wav.cpu().float()\n",
    "    \n",
    "    # 确保wav是二维的 (通道数 x 采样点数)\n",
    "    if wav.dim() == 1:\n",
    "        wav = wav.unsqueeze(0)\n",
    "    elif wav.dim() == 3:\n",
    "        wav = wav.squeeze(0)\n",
    "    \n",
    "    # 保存音频文件\n",
    "    file_path = os.path.join(output_dir, f\"sample_{i}.wav\")\n",
    "    torchaudio.save(file_path, wav, sample_rate=32000)\n",
    "    \n",
    "    print(f\"已保存音频文件：{file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
